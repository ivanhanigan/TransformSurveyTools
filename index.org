#+TITLE:Transformations Survey Tools 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* Introduction

#+name:install-tools
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
  ################################################################
  # This is documentation for tools I'm using to analyse survey data
  # about Transformational Adaptation, and an associated R package I'm
  # developing to build new tools.
  require(devtools)
  install_github("TransformSurveyTools", "ivanhanigan")
  require(TransformSurveyTools)
#+end_src

The structure of this document follows [[http://stackoverflow.com/a/1434424][Reichian LCFD approach]]. 
* General methods
** Understanding a survey
- A flow chart of how a user gains understanding of surveys
- What to look for in a user guide.

*** Flow chart 
- Step 1: Identify
  + the population, sample and variables
  + panels / waves? comparability over time
  + margin of error or anything relating to uncertainty (population and sample sizes)
  + bias: non-response bias, sampling-frame bias and self-reporting bias
  + weighting
- Step 2: Access
  - 

* Functions
** foreign

#+name:foreign
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
################################################################
# name:foreign
require(foreign)
#+end_src
   
** TreeTools

#+name:main
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
  ################################################################
  require(tree)
  require(rpart)
  require(party) 
  require(partykit) 
  
#+end_src

* Load
** read.spss

#+name:main
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
  ################################################################
  # name:main
  filename  <- "fname.sav"
  analyte  <- read.spss(filename, to.data.frame=T)
  # ignore warnings
  # str(analyte)
  # names(analyte)
  variable_labels <- attributes(analyte)$variable.labels

#+end_src

* Clean
** ReportTools: Descriptive Statistics
A really important aspect to analysing survey data is a table of descriptive statistics.  Luckily the reporttools package is here to help.  The result of the following code is a LaTeX report which you can see in the file 
*** report-code
#+name:report
#+begin_src R :session *R* :eval yes
system.file(file.path("doc", "report.pdf"), package = "TransformSurveyTools")
#+end_src
[[http://ivanhanigan.github.io/TransformSurveyTools/inst/doc/report.pdf][doc/report.pdf]]


*** all variables table
#+name:tableCode
#+begin_src R :session *R* :tangle no :eval yes
  ################################################################
  # func
  if(!require(reporttools)) install.packages("reporttools"); require(reporttools)
  require(devtools)
  install_github("TransformSurveyTools", "ivanhanigan")
  require(TransformSurveyTools)
  # load
  fpath <- system.file(file.path("extdata", "civst_gend_sector_full.csv"), package = "TransformSurveyTools")
  analyte <- read.csv(fpath)
  analyte$random <- rnorm(nrow(analyte), 0 , 1)
  for(i in 1:75)
    {
      analyte[,ncol(analyte) + 1] <- rnorm(nrow(analyte), 10 , 20)    
    }
  names(analyte)
  str(analyte)
  data_continuous <- numeric(0) 
  for(i in 1:length(names(analyte)))
    {
      if(is.numeric(analyte[,i]))
          {
              data_continuous <- c(data_continuous, i)
          }
    }
  # clean        
  str(analyte[,data_continuous])
  str(analyte[,-data_continuous])
  # do
  sink('inst/doc/tab4.tex')
  tableContinuous(vars = analyte[,data_continuous],
                  stats = c("n", "min", "mean", "median",
                    "max", "iqr", "na"),
                  cap = "Table of continuous variables.", lab = "tab:table4",
                  caption.placement = "top",
                  longtable = TRUE, add.to.row = list(pos = list(0), 
                  command = "\\hline \\endhead "))
  sink()
  
  x.big <- analyte[,-data_continuous]
  sink('inst/doc/tab5.tex')
  tableNominal(vars = x.big, cap = "Table of nominal variables",
               vertical = FALSE,
               lab = "tab:table5", longtable = TRUE,
               caption.placement = "top")
  
  sink()
     
#+end_src

#+RESULTS: tableCode


** TODO Recoding: collapse into smaller groups (e.g. Trichotomise to low, med, high)
https://www.isixsigma.com/topic/margin-of-errorci-for-ordinal-data/#post-110267
What some consultants in marketing research do is to collapse the
categories and then build confidence intervals around these
categories. For example: they often combine 7/6, 5/4 and 1/2/3 and
construct the interval around those three categories. While this
defeats the original purpose of the Likert scale (approximating an
interval scale) it has the advantage of being easy to comprehend by
management. You can then run proportion difference tests on each of
the three categories over time. Consultants typically donâ€™t even
adjust the alpha level for the fact that now you are running three
tests instead of 1 test. Also, many executives care more about your
top two and bottom three categories (on a 7-point Likert scale) than
anything that is in the middle. This approach is only used when you
have at least 7 categories. For a 10-point Likert scale the groupings
are: 1/2/3/4, 5/6, 7/8, 9/10.

** Reshape: To Long
** Reshape: To Wide
** Summarise
* Do
** COMMENT Misclassification Error Rate for Classification Trees
** COMMENT Deviance Based Measures of Descriptive Power for Classification Trees
*** Computing-and-using-deviance-with-classification-trees-Ritschard, G. (2006).
I'm reading Ritschard, G. (2006). Computing and using the deviance with classification trees. In Compstat 2006 - Proceedings in Computational Statistics 17th Symposium Held in Rome, Italy, 2006. Retrieved from http://link.springer.com/chapter/10.1007%2F978-3-7908-1709-6_5

This is implemented in SPSS code. I'll try to develop R code to do these tests.

First I'll get the data out of their paper and fit the tree in figure 1

*** sample-tree-data
#+name:tree-deviance
#+begin_src R :session *R* :tangle inst/doc/tree-data.r :eval no
  #########################################
  # func
  require(rpart)
  require(partykit) 
  
  # load
  civst_gend_sector  <- read.csv(textConnection(
      "civil_status gender activity_sector number_of_cases
           married   male         primary              50
           married   male       secondary              40
           married   male        tertiary               6
           married female         primary               0
           married female       secondary              14
           married female        tertiary              10
            single   male         primary               5
            single   male       secondary               5
            single   male        tertiary              12
            single female         primary              50
            single female       secondary              30
            single female        tertiary              18
  divorced/widowed   male         primary               5
  divorced/widowed   male       secondary               8
  divorced/widowed   male        tertiary              10
  divorced/widowed female         primary               6
  divorced/widowed female       secondary               2
  divorced/widowed female        tertiary               2
  "),sep = "")
  # save this for use later
  dir.create("inst/extdata", recursive=T)
  write.csv(civst_gend_sector, "inst/extdata/civst_gend_sector.csv", row.names = F)
  # clean
  str(civst_gend_sector)
  
  # do
  fit <- rpart(civil_status ~ gender + activity_sector,
               data = civst_gend_sector, weights = number_of_cases,
               control=rpart.control(minsplit=1))
  # NB need minsplit to be adjusted for weights.
  summary(fit)
    
  # report
  plot(fit, margin=.1)
  text(fit, use.n = TRUE)
  title("fit")
  
  # nicer plots
  png("images/fit1.png", 1000, 480)
  plot(as.party(fit))
  dev.off()  
#+end_src
*** COMMENT cuts
**** COMMENT DEPRECATED get-data-from-pdf-code
#+name:get-data-from-pdf
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:get-data-from-pdf
  # these data are in a table in the pdf but not that easy to copy and paste.
  gender <- c("male", 
  "male", 
  "male", 
  "female",
  "female",
  "female",
  "male",
  "male",
  "male",
  "female",
  "female",
  "female",
  "male", 
  "male", 
  "male", 
  "female",
  "female",
  "female")
  
  civil_status <- c("married", "married", "married", "married", "married", "married",
  "single", "single", "single", "single", "single", "single",
  "divorced/widowed", "divorced/widowed", "divorced/widowed", "divorced/widowed",
  "divorced/widowed", "divorced/widowed")
  
  activity_sector <- c("primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary")
  
  number_of_cases <- c(50, 40, 6, 0,
  14, 10, 5, 5,
  12, 50, 30, 18, 5, 8,
  10, 6, 2, 2)
  
  ls()
  civst_gend_sector <- as.data.frame(cbind(civil_status, gender, activity_sector, number_of_cases))
  
  # clean
  civst_gend_sector[4:6,]
  civst_gend_sector$number_of_cases <- as.numeric(as.character(civst_gend_sector$number_of_cases))
  civst_gend_sector  
  
  
#+end_src
*** Reproduce the figure from the paper
The figure in the paper can be checked against our results (and also the improved plot from the party package might be used).

[[file:images/fit1.png]]
*** One row per case or using weights?
Using the case weights like above is convenient especially when datasets are very large, but caused problems in model fitting for me (tree failed to compute a deviance when done this way but succeeded with a dataset expanded so the data.frame is transformed into one in which each row is an observation.
#+name:reassurance-re-weights
#+begin_src R :session *R* :tangle inst/doc/tree-data2.r :eval no
  ################################################################
  # name:reassurance-re-weights
   
  # just to reasure myself I understand what case weights do, I'll make
  # this into a survey dataset with one row per respondent
  df <- as.data.frame(matrix(NA, nrow = 0, ncol = 3))
  for(i in 1:nrow(civst_gend_sector))
      {
      #    i <- 1
          n <- civst_gend_sector$number_of_cases[i]
          if(n == 0) next
          for(j in 1:n)
              {
                df <- rbind(df, civst_gend_sector[i,1:3])              
              }
   
      }
  # save this for use later
  write.csv(df, "inst/extdata/civst_gend_sector_full.csv", row.names = F)
  # clean
  nrow(df)
  str(df)
  fit1 <- rpart(civil_status ~ gender + activity_sector, data = df)
  summary(fit1)
  
  # report
  par(mfrow=c(1,2), xpd = NA) 
  plot(fit)
  text(fit, use.n = TRUE)
  title("fit")
  plot(fit1)
  text(fit1, use.n = TRUE)
  title("fit1")
  # great these are the same which is what we'd hoped to see
  
#+end_src

*** Chisquare test of deviance for Classification trees
I want to use the deviance as well as the misclassification error rate for measuring the descriptive power of the tree.  Using the tree package we can access the deviance of the fitted Classification tree.  Ripley's tree package is the only one I found to give me deviance for classification trees, the other packages only return this for regression trees.

If we look at the reduction in deviance between the Null model and the fitted tree we can say that the tree explains about XYZ% of the variation. We can also test if this is a statistically significant reduction (based on a chi-squared test), but should also comment about how much explanation this is in practical terms.

*** COMMENT cut
The attached papers suggest a method to test differences between nested trees ie testing the difference with the root node with a Chi-square statistic (equivalent of the usual method used in logistic regression).
*** COMMENT reminder-of-method-in-logistic-regression-code
#+name:reminder-of-method-in-logistic-regression
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:reminder-of-method-in-logistic-regression
  # rewritten from http://data.princeton.edu/r/glms.html
  require(foreign)
  require(reshape)
  require(plyr)
  
  cuse <- read.dta("http://data.princeton.edu/wws509/datasets/cuse.dta")                  
  str(cuse)
  head(cuse)
  d2 <- cast(cuse,  age + educ + desire ~ cuse, value = 'n')
  head(arrange(d2, age, educ))
  d2
  lrfit <- glm(cbind(Yes, No) ~ age + educ + desire, data = d2, family = binomial)
  lrfit
  
  ## Recall that R sorts the levels of a factor in alphabetical order. Because <25 comes before 25-29, 30-39, and 40-49, it has been picked as the reference cell for age. Similarly, high is the reference cell for education because high comes before low! Finally, R picked no as the base for wantsMore.
  
  ## If you are unhappy about these choices you can (1) use relevel to change the base category, or (2) define your own indicator variables. I will use the latter approach by defining indicators for women with high education and women who want no more children:
  
  d2$noMore <- d2$desire == "Wants no more"
  d2$hiEduc <- d2$educ == "Some"
  
  
  lrfit <- glm(cbind(Yes, No) ~  age + hiEduc + noMore, data = d2, family = binomial)
  lrfit
  
  str(summary(lrfit))
#+end_src


*** TODO Check This: R function to calculate for classification trees
The Ritschard (2006) paper (with SPSS code) describes a complicated method that includes Needing to retrieve for each case: 
- leaf number and
- profile number

I really want to use the deviance as well as the misclassification error rate for measuring the descriptive power of the tree.
Ripley's tree package is the only one I found to give me deviance for classification trees.

The Ritschard papers suggest nice methods to test differences between nested trees ie testing the difference with the root node with a Chi-square statistic (equivalent of the usual method used in logistic regression).

Is this method employed widely in analysing survey data?
I haven't turned up many references to Ritschard since he wrote these.

So let's start simple first.  The following code follows the simpler approach:
- Take the difference in the deviance for the models (less complex model minus more complex model)
- Take the difference in degrees of freedom for the models
- difference between less complex and more complex model follows chi-square distribution

*** COMMENT http://www.stat.ufl.edu/~winner/sta6127/chapter15.ppt
slide 22 
Two statistics are used to test whether a model is appropriate: the Pearson chi-square statistic and the likelihood ratio (aka Deviance) statistic
slide 28
Under hypothesis that less complex (reduced) model is adequate, difference follows chi-square distribution
*** R-tree.chisq
*** R code
#+name:tree.chisq
#+begin_src R :session *R* :tangle R/tree.chisq.r :eval no
  ################################################################
  # name:tree.chisq
  tree.chisq <- function(null_model, fitted_model)
  {
      # TODO check if these are tree model class
      fit_dev  <- summary(fitted_model)$dev
      null_dev  <- summary(null_model)$dev    
      dev  <-  null_dev - fit_dev
      df  <- summary(fitted_model)$size - summary(null_model)$size
      sig  <- 1 - pchisq(dev, df)
      sprintf("Reduction in deviance is %s percent, p-value is %s (based on a chi-squared test)",
              ((null_dev - fit_dev) / null_dev) * 100,
              sig)
  }
  
#+end_src
*** test-tree.chisq
#+name:tree.chisq
#+begin_src R :session *R* :tangle tests/test-tree.chisq.r :eval no
  # func
  require(tree)
  require(devtools)
  install_github("TransformSurveyTools", "ivanhanigan")
  require(TransformSurveyTools)
  # load locally
  # fpath  <- "inst/extdata/civst_gend_sector_full.csv"
  # or via package
  fpath <- system.file("extdata", "civst_gend_sector_full.csv", package="TransformSurveyTools")
  civst_gend_sector  <- read.csv(fpath)
  
  # clean
  str(civst_gend_sector)
  
  # do
  variables  <- names(civst_gend_sector)
  y_variable  <- variables[1]
  x_variables  <- variables[-1]
  
  # NULL
  form0  <- reformulate("1",
                        response = y_variable)
  form0
  model0 <- tree(form0, data = civst_gend_sector, method = "class")
  print(model0)
  # FIT
  form1  <- reformulate(x_variables,
                        response = y_variable)
  form1
  model1 <- tree(form1, data = civst_gend_sector, method = "class")
  print(model1)
  summary(model1)
  plot(model1)
  text(model1,pretty = 0)
  tree.chisq(null_model = model0, fitted_model = model1)
    
#+end_src
**** COMMENT test- deprecated - broken
#+begin_src R :session *R* :tangle tests/test-tree.chisq.r :exports none :eval no
  ################################################################
  # name:tree.chisq
  # func
  require(tree)
  
  # load
  fpath  <- "inst/extdata/civst_gend_sector.csv"
  # or
  #fpath <- system.file("extdata", "my_raw_data.csv",
  # package="my_package")
  civst_gend_sector  <- read.csv(fpath)
  
  # clean
  str(civst_gend_sector)
  
  # do
  variables  <- names(civst_gend_sector)
  y_variable  <- variables[1]
  x_variables  <- variables[-c(1,4)]
  weight  <- civst_gend_sector[,variables[4]]
  # NULL
  form0  <- reformulate("1",
                        response = y_variable)
  form0
  model0 <- tree(form0, data = civst_gend_sector, method = "class", weights = weight)
  # FIT
  form1  <- reformulate(x_variables,
                        response = y_variable)
  form1
  model1 <- tree(form1, data = civst_gend_sector, method = "class", weights = weight)
  # this produces a NaN on node 4!
  ## > model1 <- tree(form1, data = civst_gend_sector, method = "class", weights = weight)
  ## > print(model1)
  ## node), split, n, deviance, yval, (yprob)
  ##       * denotes terminal node
  
  ## 1) root 273 534.00 married ( 0.12088 0.43956 0.43956 )  
  ##   2) gender: female 132 191.80 single ( 0.07576 0.18182 0.74242 )  
  ##     4) activity_sector: primary 56    NaN single ( 0.10714 0.00000 0.89286 ) *
  ##     5) activity_sector: secondary,tertiary 76 123.00 single ( 0.05263 0.31579 0.63158 ) *
  ##   3) gender: male 141 239.00 married ( 0.16312 0.68085 0.15603 )  
  ##     6) activity_sector: primary,secondary 113 145.70 married ( 0.11504 0.79646 0.08850 ) *
  ##     7) activity_sector: tertiary 28  59.41 single ( 0.35714 0.21429 0.42857 ) *
  model1 <- tree(form1, data = df, method = "class")
  ## > print(model1)
  ## node), split, n, deviance, yval, (yprob)
  ##       * denotes terminal node
  
  ## 1) root 273 534.00 married ( 0.12088 0.43956 0.43956 )  
  ##   2) gender: female 132 191.80 single ( 0.07576 0.18182 0.74242 )  
  ##     4) activity_sector: primary 56  38.14 single ( 0.10714 0.00000 0.89286 ) *
  ##     5) activity_sector: secondary,tertiary 76 123.00 single ( 0.05263 0.31579 0.63158 ) *
  ##   3) gender: male 141 239.00 married ( 0.16312 0.68085 0.15603 )  
  ##     6) activity_sector: primary,secondary 113 145.70 married ( 0.11504 0.79646 0.08850 ) *
  ##     7) activity_sector: tertiary 28  59.41 single ( 0.35714 0.21429 0.42857 ) *
  ## > 
  model1 <- tree(form1, data = df, method = "class")
  print(model1)
  plot(model1)
  # can't plot if used civst_gender_sector
  text(model1,pretty = NULL)
  
  
#+end_src
**** COMMENT man-tree.chisq
#+name:tree.chisq
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:tree.chisq

#+end_src
*** main-tree-model
#+name:tree.chisq
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
source("tests/test-tree.chisq.r")
#+end_src
** using rules
*** funcs for using rules
#+name:using rules
#+begin_src R :session *R* :tangle no :exports none :eval yes
#### name:using rules ####
# http://www.togaware.com/datamining/survivor/Convert_Tree.html
list.rules.rpart <- function(model)
{
  if (!inherits(model, "rpart")) stop("Not a legitimate rpart tree")
  #
  # Get some information.
  #
  frm     <- model$frame
  names   <- row.names(frm)
  ylevels <- attr(model, "ylevels")
  ds.size <- model$frame[1,]$n
  #
  # Print each leaf node as a rule.
  #
  for (i in 1:nrow(frm))
  {
    if (frm[i,1] == "<leaf>")
    {
      # The following [,5] is hardwired - needs work!
      cat("\n")
      cat(sprintf(" Rule number: %s ", names[i]))
      cat(sprintf("[yval=%s cover=%d (%.0f%%) prob=%0.2f]\n",
                  ylevels[frm[i,]$yval], frm[i,]$n,
                  round(100*frm[i,]$n/ds.size), frm[i,]$yval2[,5]))
      pth <- path.rpart(model, nodes=as.numeric(names[i]), print.it=FALSE)
      cat(sprintf("   %s\n", unlist(pth)[-1]), sep="")
    }
  }
}
# hacked to allow subsetting of the data frame to look at the contents
# of a terminal node
list.rules.rpart2 <- function(
  model=fit2
  )
{
  if (!inherits(model, "rpart")) stop("Not a legitimate rpart tree")
  #
  # Get some information.
  #
  datname <- model$call["data"]
  frm     <- model$frame
  names   <- row.names(frm)
  ylevels <- attr(model, "ylevels")
  ds.size <- model$frame[1,]$n
  #
  # Print each leaf node as a rule.
  #
  for (i in 1:nrow(frm))
  {
    if (frm[i,1] == "<leaf>")
    {
      print(i)
      # The following [,5] is hardwired - needs work!
      cat("\n")
      cat(sprintf(" Rule number: %s ", names[i]))
      cat(sprintf("[yval=%s cover=%d (%.0f%%) prob=%0.2f]\n",
                  ylevels[frm[i,]$yval], frm[i,]$n,
                  round(100*frm[i,]$n/ds.size), frm[i,]$yval2[,5]))
      pth <- path.rpart(model, nodes=as.numeric(names[i]), print.it=FALSE)
      cat(sprintf("   %s\n", unlist(pth)[-1]), sep="")
      txt <- paste(datname,"[",datname,"$",
                   paste(unlist(pth)[-1], sep="", collapse = paste("\n & ",datname,"$", sep = ""))
                   ,
                   ",]", sep = "")
      cat(txt)
      df <- eval(
        parse(text = txt)
        )
      cat("\n")
      print(disentangle::data_dict(df, as.character(model$terms[[2]])))
    }
  }
}

#+end_src

#+RESULTS: using

*** COMMENT test using rules
#+name:test using rules
#+begin_src R :session *R* :tangle no :exports none :eval no
  #### name:test using rules ####
  fit2 <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis)
  plot(fit2)
  text(fit2)
  list.rules.rpart(fit2)
  list.rules.rpart2(fit2)
#+end_src
*** set up for rules2subset func
#+name:test
#+begin_src R :session *R* :tangle test.R :exports none :eval yes
  #### name:test ####
  library(readxl)
  rulesdf <- read_excel("/home/ivan_hanigan/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data Cleaning/CleaningIH/decision_tree_for_piping_logic3.xlsx")
  rulesdf <- rulesdf[1:6,1:4]
  rulesdf
  #dat[] <- lapply(dat, as.character)
  
  #str(dat)
  
#+end_src

#+RESULTS: test
| Rule 1 | PANEL == 'Online Panel' | cNATDISdroughthappen12mo == 'Yes' | (cFMRassistmgefarm == 'Yes'                            | cFMRmanagefarm == 'Yes') |
| Rule 2 | PANEL == 'Online Panel' | cNATDISdroughthappen12mo == 'Yes' | (cFMRassistmgefarm != 'Yes' & cFMRmanagefarm != 'Yes') |                          |
| Rule 3 | PANEL == 'Online Panel' | cNATDISdroughthappen12mo != 'Yes' | nil                                                    |                          |
| Rule 4 | PANEL != 'Online Panel' | PANEL != 'Community Survey'       | cNATDISdroughthappen12mo == 'Yes'                      |                          |
| Rule 5 | PANEL != 'Online Panel' | PANEL != 'Community Survey'       | cNATDISdroughthappen12mo != 'Yes'                      |                          |
| Rule 6 | PANEL != 'Online Panel' | PANEL == 'Community Survey'       | nil                                                    |                          |

#+RESULTS: using

*** rules2subset func
#+name:using rules
#+begin_src R :session *R* :tangle R/rules2subset.R :exports none :eval yes
  #### name:using rules ####
  # http://www.togaware.com/datamining/survivor/Convert_Tree.html
  rules2subset <- function(
    rulesdf = rulesdf
    ,
    datname = "dat"
    ,
    response = "cNATDISdroughtCHANGEDofffrmwrk"
    ,
    show_r = F
    , 
    expected_values = NULL
  )
  {
    expected_values = 'expected_value'
    if (!is.null(expected_values)) {
      expectations <- rulesdf[,which(names(rulesdf) == expected_values)]
      rulesdf <- rulesdf[,-which(names(rulesdf) == expected_values)]
      names(rulesdf)
  
    }
    
    totals <- as.data.frame(matrix(NA, ncol = 3, nrow = 0))
    names(totals) <- c("Rule", "Subtotal", "RuleText")
   for (i in 1:nrow(rulesdf))
    {
  #    i=1
  #    if (frm[i,1] == "<leaf>")
  #    {
        # The following [,5] is hardwired - needs work!
  #      cat("\n")
        cat(sprintf("--------\n\n Rule number: %s \n\n", rulesdf[i, 1]))
  #      cat(sprintf("[yval=%s cover=%d (%.0f%%) prob=%0.2f]\n",
  #                  ylevels[frm[i,]$yval], frm[i,]$n,
  #                  round(100*frm[i,]$n/ds.size), frm[i,]$yval2[,5]))
        rules <- rulesdf[i,-1]
        rules <- rules[!is.na(rules)]
        pth <- rules
        cat(sprintf("   %s\n", unlist(pth)), sep="")
        cat(sprintf("Expected values: %s", expectations[i]))
        txt1 <- sprintf('attach(%s)', datname)
        txt <- paste(datname,"[",
                     paste(unlist(pth), sep="", collapse = paste("\n & ", sep = ""))
                     ,
                     ",]", sep = "")
        
        ## txt <- paste(datname,"[",datname,"$",
        ##              paste(unlist(pth), sep="", collapse = paste("\n & ",datname,"$", sep = ""))
        ##              ,
        ##              ",]", sep = "")
        txt2 <- sprintf('detach(%s)', datname)
        txt3 <- paste("with(", datname,", ", txt, ")", sep = '')
        cat("\n")      
        if(show_r){
          cat(txt3)
          cat("\n\n")
        }
        df <- eval(
          parse(text = txt3)
          )
        #str(df)
  
        dd <- disentangle::data_dict(df, response)
        print(dd)
        cat(sprintf("Subtotal: %s\n", sum(dd$Count)))
  subtotal <- data.frame(Rule = rulesdf[i,1], Subtotal = sum(dd$Count),
                         RuleText = paste(unlist(pth), sep="", collapse = paste(" & ", sep = ""))
                         )
  #subtotal
  
      totals <- rbind(totals, subtotal)
      }
  grandtotal <- data.frame(Rule = 'GrandTotal', Subtotal =   sum(totals$Subtotal),
                         RuleText = ''
                         )
    totals <- rbind(totals, grandtotal)
    print(totals)
    return(totals)
  }
#+end_src

*** COMMENT test using rules
#+name:test using rules
#+begin_src R :session *R* :tangle no :exports none :eval no
  #### name:test using rules ####
  fit2 <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis)
  plot(fit2)
  text(fit2)
  list.rules.rpart(fit2)
  list.rules.rpart2(fit2)
#+end_src

** Confidence intervals around a proportion
*** COMMENT adjustedWald
#+name:adjustedWald
#+begin_src R :session *R* :tangle R/adjustedWald.R :exports none :eval no
  # adjusted wald from http://www.measuringux.com/adjustedwald.htm
  z <- 1.96
  padj <- (n*p + (z^2)/2)/(n + z^2)  
  nadj <- n + z^2  
  # And finally, the calculation of the confidence interval:
  d2$ci  <- z * sqrt(padj*(1 - padj)/nadj)  
  d2$uci  <- padj + z * sqrt(padj*(1 - padj)/nadj)  
  d2$lci  <- padj - z * sqrt(padj*(1 - padj)/nadj)

#+end_src
** crosstabulating a list of variables (weighted data) by various dimensions and returning unweighted n (and CI for nominal data)
*** COMMENT feed
#+name:feed
#+begin_src R :session *R* :tangle no :exports none :eval yes
#### name:feed ####
indat<-read.csv("inst/extdata/crosstab_weighted_survey.csv")
indat
#+end_src

#+RESULTS: feed
| 0.1 survey data    | 2015 RWS data set_Masterfile_25May2016        | master       | check the version, update if desired | ~/Private/Regional Wellbeing Survey/RWSurvey 2015/RWS Data/MASTER                                           |
| 0.2 farmer type    | Farmer type coding.csv                        | farmertype   |                                      | ~/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data/RWS Data Analysis/Farmer type coding             |
| 0.3 weights        | TestOutweightsDataset_NoEdu_Cut.csv           | weights      |                                      | ~/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data/RWS Data Analysis/Weighting process/data_derived |
| 0.4 load metdata   | 2015 RWS Metadata.xlsx                        | metadata     |                                      | ~/Private/Regional Wellbeing Survey/RWSurvey 2015/RWS Data/MASTER                                           |
| 0.5 regions        | ReportingRegions.shp                          | regions      |                                      | ~/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data/RWS Data Analysis/ReportingRegions               |
| 0.6 input data     | master, farmertype, weights, metadata,regions | indat        |                                      |                                                                                                             |
| 1.1 setup section  |                                               | sectionlabel |                                      |                                                                                                             |
| 1.2 list the vars  | metadata                                      | mainvars     |                                      |                                                                                                             |
| 1.3 select the dim | dimensions                                    | dimension    |                                      |                                                                                                             |
| 1.4 set the scope  | sectionlabel,mainvars,dimension               | scope        |                                      |                                                                                                             |
| 1.5 analysis data  | scope, indat                                  | indat2       |                                      |                                                                                                             |

*** COMMENT show
#+name:show
#+begin_src R :session *R* :tangle no :exports none :eval yes
  #### name:show ####
  require(disentangle)
  require(stringr)
  indat<-read.csv("inst/extdata/crosstab_weighted_survey.csv", as.is = T, strip.white = T)
  indat[,1:3]
  str(indat)
  nodes <- newnode(indat, "step", "inputs", "outputs")
  #DiagrammeR::grViz(nodes)
  sink("file_name.dot")
  cat(nodes)
  sink()# If graphviz is installed and on linux
  system("dot -Tpdf file_name.dot -o file_name.pdf")
  #browseURL("file_name.pdf")
#+end_src
*** step 0 funcs and load
**** COMMENT Step 0 load libraries
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  #### name:init ####
  library(sqldf)  
  library(survey)
  library(readxl)
  library(car)
  library(data.table)
#+end_src

#+RESULTS:
| car         |
| readxl      |
| survey      |
| grid        |
| sqldf       |
| RSQLite     |
| DBI         |
| gsubfn      |
| proto       |
| stringr     |
| disentangle |
| stats       |
| graphics    |
| grDevices   |
| utils       |
| datasets    |
| methods     |
| base        |

**** COMMENT Step 0 load master
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  
  projdir <- "/home/ivan_hanigan/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Reports/Drought and extreme weather"
  
  indir_master <- "/home/ivan_hanigan/Private/Regional Wellbeing Survey/RWSurvey 2015/RWS Data/MASTER"
  #setwd(indir_master)
  #dir()
  
  infile_master <- "2015 RWS data set_Masterfile_25May2016.csv"
  
  master <- read.csv(file.path(indir_master, infile_master))
  nrow(master)
  # 13303
  ncol(master)
  # 1032
#+end_src
**** COMMENT Step 0 load metadata
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  dir(indir_master)
  # first read told me that there are 9 cols and it failed to identify
  # the type as text so set this
  metadata  <- read_excel(file.path(indir_master, "2015 RWS Metadata_25May2016.xlsx"),
                          col_types = rep("text", 9))
  str(metadata)
  names(as.data.frame(metadata))
  metadata$sortorder <- row.names(metadata)
  
  
#+end_src
**** COMMENT Step 0 load farmer type notes
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval no
  
  ## -    Notfarmer1DrylandFarmer2Irrigator3UnspecFmr4: This variable is my best estimate of whether 
  ## a respondent was (1) Not a farmer, (2) Dryland farmer, (3) Irrigator or (4) Farmer unspecified. It 
  ## has been produced based not only on the I am a dryland farmer and I irrigate all or part of my 
  ## land variable, but also includes inferred values for around 400 of the farmers who did not 
  ## answer those questions, based on (i) what they produce on the farm, (ii) whether they answered 
  ## later irrigation questions in a way suggesting they are an irrigator, and (iii) their geographic 
  ## location (there is no irrigation in some districts, which allowed me to infer the person was a 
  ## dryland farmer)
  ## -    FarmerTypeSimple: This variable is based on what a farmer described as their most important 
  ## farm business activity AND their major farming activities. Data have been coded to the most 
  ## common combinations. I am currently writing a full metadata entry for this variable as the logic 
  ## used to classify farmers who did multiple activities is complex. 
#+end_src
**** COMMENT Step 0 load farmer type
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  indir_farmers  <- "~/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data/RWS Data Analysis/Farmer type coding"
  infile_farmers <- "Farmer type coding.csv"
  dat_farmers <- read.csv(file.path(indir_farmers, infile_farmers))
  nrow(dat_farmers)
  #13304
  ncol(dat_farmers)
  #75
  names(dat_farmers)
  farmers <- dat_farmers[,c("cSURVID", "Notfarmer1DrylandFarmer2Irrigator3UnspecFmr4",
                                "FarmerTypeSimple")]
  head(farmers)
#+end_src
**** COMMENT Step 0 load weights
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  
  indir_wts <- "~/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Data/RWS Data Analysis/Weighting process/data_derived"
  
  dir(indir_wts)
  infile_wts  <- "TestOutweightsDataset_NoEdu_Cut.csv"
  
  weights <- read.csv(file.path(indir_wts, infile_wts))
  str(weights)
  weight <- "GReg_Weight_NoEdu_Cut"
  wtvar <- c("cSURVID", weight)
  weights <- weights[,wtvar]
  head(weights)
  dim(weights)
  # [1] 13304     2
  
#+end_src
**** COMMENT Step 0 load merge
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_load.R :exports none :eval yes
  dat  <- merge(master, farmers)
  dat  <- merge(dat, weights)
  #str(dat[1:4])
  
  
#+end_src

**** COMMENT Step 1 define scope
#+begin_src R :session *R* :tangle no :exports none :eval yes
  flist <- dir("/home/ivan_hanigan/ownCloud/Regional Wellbeing Study/RWSurvey 2015/RWS Reports/Drought and extreme weather/figures_and_tables")
  flist <- strsplit(flist, "\\.")
  flist2 <- do.call(rbind, flist)
  head(flist2)
  names(table(flist2[,1]))
#+end_src

#+RESULTS:
| drought_ewe                                                            |
| drought_ewe_AFFECTED                                                   |
| drought_ewe_AFFECTEDpers                                               |
| drought_ewe_AFFECTED_the_following                                     |
| drought_ewe_AFFECTED_the_following_gender                              |
| drought_ewe_AFFECTED_the_following_ReportingRegions                    |
| drought_ewe_AFFECTED_wide                                              |
| drought_ewe_age                                                        |
| drought_ewe_by_ReportingRegion                                         |
| drought_ewe_by_ReportingRegion_cNATDISbushfirehappen                   |
| drought_ewe_by_ReportingRegion_cNATDIScoldsnaphappen                   |
| drought_ewe_by_ReportingRegion_cNATDISdroughthappen12mo                |
| drought_ewe_by_ReportingRegion_cNATDISfloodhappen                      |
| drought_ewe_by_ReportingRegion_cNATDISheatwavehappen                   |
| drought_ewe_by_ReportingRegion_cNATDISseverestormcyclonehappen         |
| drought_ewe_by_ReportingRegion_farmers                                 |
| drought_ewe_by_ReportingRegion_farmers_cNATDISbushfirehappen           |
| drought_ewe_by_ReportingRegion_farmers_cNATDIScoldsnaphappen           |
| drought_ewe_by_ReportingRegion_farmers_cNATDISdroughthappen12mo        |
| drought_ewe_by_ReportingRegion_farmers_cNATDISfloodhappen              |
| drought_ewe_by_ReportingRegion_farmers_cNATDISheatwavehappen           |
| drought_ewe_by_ReportingRegion_farmers_cNATDISseverestormcyclonehappen |
| drought_ewe_cFDlossprofit                                              |
| drought_ewe_CHANGED_the_following                                      |
| drought_ewe_CHANGED_the_following_Australia                            |
| drought_ewe_CHANGED_the_following_gender                               |
| drought_ewe_CHANGED_the_following_ReportingRegions                     |
| drought_ewe_farmers                                                    |
| drought_ewe_farmers_ste                                                |
| drought_ewe_farmer_type                                                |
| drought_ewe_farmer_type_and_profitability                              |
| drought_ewe_FarmerTypeSimple                                           |
| drought_ewe_gender                                                     |
| drought_ewe_gender_age                                                 |
| drought_ewe_gender_age_notfarmer_farmer                                |
| drought_ewe_gender_farmer_type_and_profitability                       |
| drought_ewe_Notfarmer1DrylandFarmer2Irrigator3                         |
| drought_ewe_ste                                                        |
| DroughtMaps                                                            |
| DroughtMapsBOM                                                         |
| drought_personal_life                                                  |
| farm_business_planning                                                 |
| map_BOM_vs_cNATDISdrought                                              |
| map_cNATDISdroughthappen12mo                                           |
| map_cNATDISdroughthappen12mo_farmers                                   |
| map_DroughtMapsBOM                                                     |
| qc_cNATDISdroughtCHANGEDdesirefarm_wt_uwt                              |
| template                                                               |
| template_drought_ewe_groups                                            |
| versions                                                               |
**** COMMENT Step 1.0 load report_sections
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_define_scope.R :exports none :eval yes
  report_sections <- c("drought_ewe",                                                            
  "drought_ewe_AFFECTED",                                                  
  "drought_ewe_AFFECTED_the_following",                                     
  "drought_ewe_CHANGED_the_following",                                      
  "drought_ewe_farmer_type_and_profitability",                              
  "map_cNATDISdroughthappen12mo")                                           
  
  
   
#+end_src

**** COMMENT Step 2 init
#+begin_src R :session *R* :tangle inst/doc/expore_RWS_main.R :exports none :eval yes
  #### Load
  source("inst/doc/explore_RWS_load.R")
  source("inst/doc/explore_RWS_define_scope.R")
#+end_src
*** TODO Function xtab_by_dimensions
#+begin_src R :session *R* :tangle R/xtab_by_dimensions.R :exports none :eval yes
  xtab_by_dimensions <- function(
    dat = dat
    ,
    pid = "cSURVID"
    ,
    mainvar = "cNATDISdroughtAFFECTcommunity2" 
    ,
    dimension = "SDgender2"
    ,
    weights = "GReg_Weight_NoEdu_Cut"
    ,
    overall = TRUE
    ,
    extra_exclusions_mainvar = NULL # i.e. -88 N/A along with standard -999
    ,
    extra_exclusions_dimension = NULL # i.e. '' as well as standard -777
                                      # and -999
    ){
  invar <- c(pid, dimension, mainvar, weights)
  matrix(invar)
  
  # data.frame(table(dat[,dimension]))
  if(!is.null(extra_exclusions_dimension)){
    xtra <- paste("& dat[,dimension] != ", extra_exclusions_dimension, sep = "")
  } else {
    xtra <- ""
  }
  txt <- paste("datin <- dat[             
               dat[,dimension] != '-999' &
               dat[,dimension] != '-777'              
               ",xtra,"
               , invar
               ]", sep ="")
  #cat(txt)
  eval(parse(text=txt))  
  #str(datin)
  datin[,dimension] <- factor(datin[,dimension])
  #data.frame(table(datin[,dimension]))
    
  
  #mainvar
  #data.frame(table(datin[,mainvar]))  
  #head(datin)
  #str(datin)
  #summary(datin)
  if(!is.null(extra_exclusions_mainvar)){
    xtra <- paste("& datin[,mainvar] != ", extra_exclusions_mainvar, sep = "")
  } else {
    xtra <- ""
  }
  txt <- paste("datin <- datin[             
               datin[,mainvar] != '-999' &
               datin[,mainvar] != '-777'              
               ",xtra,"
               , 
               ]", sep ="")
  #cat(txt)
  eval(parse(text=txt))  
  #str(datin)
  
  datin[,mainvar] <- factor(datin[,mainvar])
  #data.frame(table(datin[,mainvar]))
  
  #outcols <-
  #summa_out <- matrix(NA, nrow = 0, ncol = outcols)
  #head(datin)
  #nrow(datin)
  # 6558
  #head(datin[,1:4])
  
  
  # unweighted n
  n <- table(datin[,dimension])
  #n
  #dat_wt <- svydesign(ids = ~Notfarmer1DrylandFarmer2Irrigator3, data
  #= datin, weights = datin$GReg_Weight_NoEdu_Cut)
  txt1 <- paste("dat_wt <- svydesign(ids = ~",mainvar,", data = datin, weights = datin$",weights,")", sep = "")
  #txt1
  eval(parse(text=txt1))    
  #summary(dat_wt)
  #str(dat_wt)
  
  txt <- paste("summa <- cbind('",mainvar,"', '",dimension,"', t(prop.table(svytable(~",mainvar,"+",dimension,", design = dat_wt),2)), n)", sep = '')
  #txt
  #qc <- t(prop.table(svytable(~cNATDISdroughthappen12mo+Notfarmer1DrylandFarmer2Irrigator3, design = dat_wt),2))
  #qc
  #cbind(qc*100,qc[,1]+qc[,2])
  eval(parse(text=txt))
  #summa
  ## summa <- c(mainvar, table(datin[,mainvar])/n, n)
  #as.data.frame(summa)
  #summa
  summa  <- cbind(summa, row.names(summa))
  ##   str(summa)
  #summa_out <- summa
  
  ## }
  #summa
  #head(summa)
  # TODO modify for number of cols
  nc <- ncol(summa)
  #nc
  d2  <- apply(summa[,3:(nc-1)], 2, as.numeric)
  #head(d2)
  d2  <- data.frame(summa[,c(1:2, nc)], round(d2, 2))
  #names(d2)  <- c("variable", "dimension", "No", "Yes", "n")
  #d2
  
  #d2  <-  cbind(summa[,nc], d2)
  names(d2)  <- c("variable", "dimension", "state", names(d2)[4:(nc)])
  row.names(d2) <- NULL
  ## d3  <- data.frame(variable = d2$variable, Disagree = rowSums(d2[,c(2:4)]),
  ##                   Neither_agree_or_disagree = d2[,5],
  ##                   Agree = rowSums(d2[,6:8])
  ##                   )
  ## d3
  ## d2 <- merge(d2, d3)  
  #d2 <- merge(mainvars_df, d2, by.x = "var", by.y = "variable")
  
  ## d2  <- sqldf("select *
  ## from d2
  ## where Yes > 0
  ## order by var, state")
  ## d2  
  ## #names(d2) <- gsub("Neither_agree_or_disagree", "Neither agree/disagree", names(d2))
  ## str(d2)
  ## paste(names(d2), sep = "", collapse = "', '")
  ## d2 <- d2[,c('var', 'state', 'dimension', 'sortorder', 'Item stem - exact wording seen by respondents', 'Item - exact wording seen by respondent OR description of variable', 'No', 'Yes', 'n', 'Piping or display logic')]
  ## d2[,2] <- paste(d2[,2], " (n=", d2$n, ")", sep = "")
  
  # adjusted wald from http://www.measuringux.com/adjustedwald.htm
  ## z <- 2
  ## # rather than 1.96
  ## padj <- (d2$n*d2$Yes + (z^2)/2)/(d2$n + z^2)
  
  ## nadj <- d2$n + z^2
  
  ## # And finally, the calculation of the confidence interval:
  
  ## d2$ci  <- z * sqrt(padj*(1 - padj)/nadj)  
  # we will use this +/- on the proportion (not the padj as recommended, because the asymmetry 
  # might look odd to our audience)
  return(d2)
  }
#+end_src
*** Step 1.1 set up mainvars
#+begin_src R :session *R* :tangle inst/doc/explore_RWS_define_scope.R :exports none :eval yes
  
  
  mainvars <- c("cNATDISdrought12moAFFECTpers",
  "cNATDISdrought12moAFFECTjobbus",
  "cNATDISdroughtAFFECThshld",
  "cNATDISdroughtAFFECTcommunity")
  

#+end_src

#+RESULTS:
| cNATDISdrought12moAFFECTpers   |
| cNATDISdrought12moAFFECTjobbus |
| cNATDISdroughtAFFECThshld      |
| cNATDISdroughtAFFECTcommunity  |
*** Step 1.2 create new mainvars by recoding
#+name:Step 0 create new variables
#+begin_src R :session *R* :tangle no :exports none :eval no
  ########################################################################################
  # clean
  ## check the piping logic does not show people who should be excluded
  
  ## collapse into smaller groups
  table(dat$cNATDISdroughtAFFECTcommunity)
  
  ## dat$cNATDISdroughtAFFECTcommunity2 <- recode(
  ##   dat$cNATDISdroughtAFFECTcommunity,
  ##   recodes = "0='0.No impact';
  ##     1:3 = '1.Negative impact';
  ##     4 = '2.Neither negative or positive';
  ##     5:7 = '3.Positive impact';
  ##     -99 = '4.Dont know'"
  ##   )
  ## as.data.frame(table(dat$cNATDISdroughtAFFECTcommunity2))
  
  for(mainvar in mainvars){
  mainvar2  <- paste(mainvar, "2", sep = "")
  txt0 <- paste("dat$",mainvar2," <- recode(dat$",mainvar,", recodes = \"0='0.No impact'; 1:3 = '1.Negative impact'; 4 = '2.Neither negative or positive'; 5:7 = '3.Positive impact'; -99 = '4.Dont know'\")",
    sep = "")
    
  txt0
  eval(parse(text=txt0))  
  }
  names(dat)
  
  # TODO add to metadata
  #as.data.frame(t(metadata[1,]))
  
  #metadata <- rbind(metadata,
  #                  c("newvar", "created from oldvar, added label for things")
  #                  )
  
#+end_src

*** Step 1.3 set up dimensions
#+begin_src R :session *R* :tangle inst/doc/expore_RWS_main.R :exports none :eval yes
  
  #### make new dimension?
  dat$Notfarmer1DrylandFarmer2Irrigator3 <- recode(dat$Notfarmer1DrylandFarmer2Irrigator3UnspecFmr4,
    recodes = "'1'='1.Non-farmer';'2'='2.Dryland farmer';'3'='3.Irrigator';'4'='4.Unspecified farmer';'-999'='-999'")
  
  dat$SDgender2 <- recode(dat$SDgender,
    recodes = "'Female     '='1.Female';
    '     Male'='2.Male';
    '-999'='-999';
    'Other'='-999';
    '     Prefer not to answer'='-999'")
  
  dat$cSDage2 <- recode(dat$cSDage,
    recodes = "'Under 18 '='Under 18';18:39='18-39'; 40:54='40-54';55:64='55-64';65:96='65+';101='65+';-999='-999'")
    
  
  dimensions  <- c("Notfarmer1DrylandFarmer2Irrigator3", "SDgender2", "cSDage2")
  names(dat)[which(names(dat) %in% dimensions)]
#+end_src
*** Step 2 collect all relevant metadata 
#+begin_src R :session *R* :tangle inst/doc/expore_RWS_main.R :exports none :eval yes
  
  mainvars_df <- data.frame(var = mainvars)
  mainvars_df
  mainvars_df <- merge(mainvars_df, metadata, by.x = "var", by.y = "Variable name")
  nrow(mainvars_df)
  names(mainvars_df)
  
  mainvars_df <-  mainvars_df[, c('sortorder', 'var',
                  "Item stem - exact wording seen by respondents",
                  "Item - exact wording seen by respondent OR description of variable",
                  "Piping or display logic")]
  
  mainvars_df <- mainvars_df[order(mainvars_df$sortorder),]
  mainvars_df[,c(1:2,4)]
#+end_src
*** Step 3 source func, load data, clean dimensions and mainvars
#+begin_src R :session *R* :tangle inst/doc/expore_RWS_main.R :exports none :eval yes
  ########################################################################################
  # func
  #rm(list = ls())
  source("R/xtab_by_dimensions.R")
  dir("inst/doc")
  source("inst/doc/explore_RWS_define_scope.R")
  ls()
  mainvars
  #dimension
  
  report_sections
  sectionlabel <- "drought_ewe_AFFECTED_the_following"
  
  ########################################################################################3
  # load
  if(!exists("dat")){
    source("inst/doc/explore_RWS_load.R")
  }
#+end_src

#+RESULTS:

*** Step 4 do xtabs
#+begin_src R :session *R* :tangle snip.R :exports none :eval yes
   
  mainvars2 <- paste(mainvars, 2, sep  = "")
                     mainvars2
  names(dat)[which(names(dat) %in% dimensions)]
  
  d2out_list <- list(0)
  for(i in 1:length(mainvars2)){
  #  i  = 1
  
    mainvar  <- mainvars2[i]
    mainvar
    d2out2_list <- list(0) 
    for(j in 1:length(dimensions)){
      dimension <- dimensions[j]
      
      d2out2_list[[j]] <- xtab_by_dimensions(dat = dat,
        pid = "cSURVID",
        mainvar = mainvar,
        dimension = dimension,
        weights = "GReg_Weight_NoEdu_Cut",
        extra_exclusions_dimension = "'Prefer not to answer'"                                         
        )
    }
    d2out_list[[i]] <- rbindlist(d2out2_list)
    
  }
  
  d2out_list
  outout <- rbindlist(d2out_list)
  
  outout
  ## write.csv(d2,
  ##           sprintf("figures_and_tables/%s.csv", sectionlabel)
  ##           , row.names=F)
  ## dir()
  ## getwd()
  
  ## for(i in 1:length(mainvars)){
  ## #  mainvars
  ## #i=1
  ##   mainvar  <- mainvars[i]
  ## print(mainvar)
  ## d3out <- d2[d2$var == mainvar,]
  ## write.csv(d3out,
  ##           sprintf("figures_and_tables/%s_%s.csv", sectionlabel, mainvar)
  ##           , row.names=F)
  
  ## }
  ## names(d2)
  ## table(d2[,c("state","levels")])
  ## widen  <- d2[,c("var", "levels", "Freq")]
  ## widen
  
  ## library(reshape)
  ## wider  <- cast(widen, var ~ levels)
  ## wider
  
  ## write.csv(wider,
  ##           sprintf("figures_and_tables/%s_wide.csv", sectionlabel)
  ##           , row.names=F)
  
#+end_src

#+RESULTS:
| cNATDISdrought12moAFFECTpers2   | Notfarmer1DrylandFarmer2Irrigator3 | 1.Non-farmer         |  0.4 | 0.36 | 0.17 | 0.04 | 0.04 | 3376 |
| cNATDISdrought12moAFFECTpers2   | Notfarmer1DrylandFarmer2Irrigator3 | 2.Dryland farmer     | 0.16 | 0.53 | 0.16 | 0.14 | 0.01 | 2095 |
| cNATDISdrought12moAFFECTpers2   | Notfarmer1DrylandFarmer2Irrigator3 | 3.Irrigator          | 0.17 | 0.49 | 0.18 | 0.15 | 0.01 |  879 |
| cNATDISdrought12moAFFECTpers2   | Notfarmer1DrylandFarmer2Irrigator3 | 4.Unspecified farmer | 0.22 | 0.34 | 0.32 | 0.09 | 0.03 |  214 |
| cNATDISdrought12moAFFECTpers2   | SDgender2                          | 1.Female             | 0.39 | 0.37 | 0.17 | 0.04 | 0.04 | 3470 |
| cNATDISdrought12moAFFECTpers2   | SDgender2                          | 2.Male               | 0.36 | 0.37 | 0.17 | 0.06 | 0.04 | 3114 |
| cNATDISdrought12moAFFECTpers2   | cSDage2                            | 18-39                | 0.42 | 0.35 | 0.13 | 0.03 | 0.07 |  716 |
| cNATDISdrought12moAFFECTpers2   | cSDage2                            | 40-54                | 0.37 | 0.39 | 0.18 | 0.04 | 0.02 | 1760 |
| cNATDISdrought12moAFFECTpers2   | cSDage2                            | 55-64                | 0.32 | 0.39 | 0.19 | 0.07 | 0.03 | 2033 |
| cNATDISdrought12moAFFECTpers2   | cSDage2                            | 65+                  | 0.37 | 0.33 | 0.16 | 0.12 | 0.01 | 2071 |
| cNATDISdrought12moAFFECTpers2   | cSDage2                            | Under 18             | 0.63 | 0.19 | 0.09 |    0 | 0.09 |    5 |
| cNATDISdrought12moAFFECTjobbus2 | Notfarmer1DrylandFarmer2Irrigator3 | 1.Non-farmer         | 0.54 | 0.27 | 0.09 | 0.04 | 0.06 | 3075 |
| cNATDISdrought12moAFFECTjobbus2 | Notfarmer1DrylandFarmer2Irrigator3 | 2.Dryland farmer     | 0.16 | 0.56 | 0.11 | 0.15 | 0.01 | 2031 |
| cNATDISdrought12moAFFECTjobbus2 | Notfarmer1DrylandFarmer2Irrigator3 | 3.Irrigator          | 0.15 | 0.56 | 0.11 | 0.16 | 0.01 |  865 |
| cNATDISdrought12moAFFECTjobbus2 | Notfarmer1DrylandFarmer2Irrigator3 | 4.Unspecified farmer | 0.24 | 0.58 | 0.07 | 0.09 | 0.01 |  190 |
| cNATDISdrought12moAFFECTjobbus2 | SDgender2                          | 1.Female             | 0.53 | 0.28 | 0.08 | 0.04 | 0.07 | 3248 |
| cNATDISdrought12moAFFECTjobbus2 | SDgender2                          | 2.Male               | 0.46 | 0.32 |  0.1 | 0.08 | 0.05 | 2931 |
| cNATDISdrought12moAFFECTjobbus2 | cSDage2                            | 18-39                | 0.48 | 0.32 | 0.09 | 0.05 | 0.06 |  710 |
| cNATDISdrought12moAFFECTjobbus2 | cSDage2                            | 40-54                | 0.48 | 0.31 |  0.1 | 0.05 | 0.06 | 1725 |
| cNATDISdrought12moAFFECTjobbus2 | cSDage2                            | 55-64                | 0.53 | 0.25 |  0.1 | 0.07 | 0.06 | 1971 |
| cNATDISdrought12moAFFECTjobbus2 | cSDage2                            | 65+                  | 0.58 | 0.24 | 0.06 | 0.09 | 0.03 | 1770 |
| cNATDISdrought12moAFFECTjobbus2 | cSDage2                            | Under 18             | 0.63 | 0.19 |    0 |    0 | 0.18 |    5 |
| cNATDISdroughtAFFECThshld2      | Notfarmer1DrylandFarmer2Irrigator3 | 1.Non-farmer         | 0.49 | 0.28 | 0.12 | 0.04 | 0.07 | 3243 |
| cNATDISdroughtAFFECThshld2      | Notfarmer1DrylandFarmer2Irrigator3 | 2.Dryland farmer     |  0.2 | 0.51 | 0.15 | 0.12 | 0.03 | 2010 |
| cNATDISdroughtAFFECThshld2      | Notfarmer1DrylandFarmer2Irrigator3 | 3.Irrigator          | 0.22 | 0.43 | 0.17 | 0.14 | 0.03 |  837 |
| cNATDISdroughtAFFECThshld2      | Notfarmer1DrylandFarmer2Irrigator3 | 4.Unspecified farmer | 0.23 | 0.54 | 0.11 | 0.11 | 0.01 |  192 |
| cNATDISdroughtAFFECThshld2      | SDgender2                          | 1.Female             | 0.44 | 0.33 | 0.13 | 0.05 | 0.05 | 3342 |
| cNATDISdroughtAFFECThshld2      | SDgender2                          | 2.Male               | 0.49 | 0.27 | 0.11 | 0.05 | 0.08 | 2960 |
| cNATDISdroughtAFFECThshld2      | cSDage2                            | 18-39                | 0.47 | 0.31 |  0.1 | 0.05 | 0.08 |  711 |
| cNATDISdroughtAFFECThshld2      | cSDage2                            | 40-54                | 0.46 | 0.31 | 0.13 | 0.05 | 0.06 | 1736 |
| cNATDISdroughtAFFECThshld2      | cSDage2                            | 55-64                | 0.45 |  0.3 | 0.15 | 0.05 | 0.06 | 1964 |
| cNATDISdroughtAFFECThshld2      | cSDage2                            | 65+                  | 0.49 | 0.26 | 0.11 | 0.09 | 0.06 | 1887 |
| cNATDISdroughtAFFECThshld2      | cSDage2                            | Under 18             |    0 | 0.19 |    0 | 0.63 | 0.18 |    5 |
| cNATDISdroughtAFFECTcommunity2  | Notfarmer1DrylandFarmer2Irrigator3 | 1.Non-farmer         | 0.03 | 0.66 | 0.11 | 0.12 | 0.08 | 3383 |
| cNATDISdroughtAFFECTcommunity2  | Notfarmer1DrylandFarmer2Irrigator3 | 2.Dryland farmer     | 0.09 | 0.59 | 0.11 | 0.17 | 0.03 | 2089 |
| cNATDISdroughtAFFECTcommunity2  | Notfarmer1DrylandFarmer2Irrigator3 | 3.Irrigator          | 0.06 | 0.57 | 0.12 | 0.16 | 0.08 |  871 |
| cNATDISdroughtAFFECTcommunity2  | Notfarmer1DrylandFarmer2Irrigator3 | 4.Unspecified farmer | 0.08 | 0.41 | 0.08 | 0.39 | 0.05 |  214 |
| cNATDISdroughtAFFECTcommunity2  | SDgender2                          | 1.Female             | 0.02 | 0.68 |  0.1 | 0.11 | 0.08 | 3482 |
| cNATDISdroughtAFFECTcommunity2  | SDgender2                          | 2.Male               | 0.04 | 0.63 | 0.12 | 0.14 | 0.06 | 3095 |
| cNATDISdroughtAFFECTcommunity2  | cSDage2                            | 18-39                | 0.02 |  0.7 | 0.08 |  0.1 | 0.09 |  717 |
| cNATDISdroughtAFFECTcommunity2  | cSDage2                            | 40-54                | 0.03 | 0.69 | 0.12 |  0.1 | 0.05 | 1758 |
| cNATDISdroughtAFFECTcommunity2  | cSDage2                            | 55-64                | 0.02 |  0.6 | 0.13 | 0.16 | 0.09 | 2030 |
| cNATDISdroughtAFFECTcommunity2  | cSDage2                            | 65+                  | 0.08 | 0.46 | 0.18 | 0.22 | 0.06 | 2067 |
| cNATDISdroughtAFFECTcommunity2  | cSDage2                            | Under 18             |    0 | 0.73 |    0 | 0.09 | 0.18 |    5 |
*** COMMENT snip
#+begin_src R :session *R* :tangle snip.R :exports none :eval no
  #### name:snip ####

  ########################################################################################3
  # do
  d2out <- xtab_by_dimensions(
    dat = dat
    ,
    pid = "cSURVID"
    ,
    mainvar = "cNATDISdroughtAFFECTcommunity2" 
    ,
    dimension = "FarmerTypeSimple"
    ,
    weights = "GReg_Weight_NoEdu_Cut"
    ,
    recodes = NULL
    ,
    overall = TRUE
    ,
    extra_exclusions_mainvar = NULL 
    ,
    extra_exclusions_dimension = "''" 
    )
  
  d2out


    
  
  recodes = "0='0.No impact'; 1:3 = '1.Negative impact'; 4 = '2.Neither negative or positive'; 5:7 = '3.Positive impact'; -99 = '4.Dont know'"
  if(!is.null(recodes)){
  #### recode the mainvar  
  mainvar2  <- paste(mainvar, "2", sep = "")
  # TODO how to include/exclude extra like N/A?
  #if net 2 pos
  txt0 <- paste("datin$",mainvar2," <- car::recode(datin$",mainvar,", recodes = \"", recodes, "\")",
                sep = "")
  
  #if reduced - increased
  #  txt0 <- paste("datin$",mainvar2," <- recode(datin$",mainvar,", recodes = \"1:3 = '1.Reduced'; 4 = '2.Neither reduced or increased'; 5:7 = '3.Increased'; -99 = '4.Dont know'\")",
  #                sep = "")
  # if disagree-agree
  
  
  cat(txt0)
  eval(parse(text=txt0))
  datin[,mainvar2]  <- factor(datin[,mainvar2])
  #table(datin[,c(mainvar2, mainvar)])
  }
  
#+end_src

